{% extends 'base.html' %}

{% block body %}

<style>
    .listening {
        background-color: brown;
        border: 1px solid brown;
        color: #fff;
    }
</style>

<div class="container">
    <div class="h-100 p-5 text-bg-dark rounded-3">
        <h2>Speech to text APP</h2>
        <p>Real-time transcription playground using the Web Speech.</p>
        <button class="btn btn-outline-light" type="button" id="speechStart">Speech</button>
    </div>
    <p id="output"></p>


    <button id="button" onclick="toggleStartStop()" class="btn btn-outline-light" type="button">Start</button>
    <div style="border:dotted;padding:10px">
        <span id="final_span"></span>
        <span id="interim_span" style="color:grey"></span>
    </div>
</div>
<!-- https://wicg.github.io/speech-api/#dom-speechrecognition-lang -->
<!-- <script>
    const containerWrapper = document.querySelector('.container');

    async function fetchAPI() {
        let url = '/api/';
        try {
            let res = await fetch(url);
            return await res.json();
        } catch (error) {
            console.log(error);
        }
    };

    async function wishperAction() {
        const wishperData = await fetchAPI()
        containerWrapper.innerHTML += `
            <p class="fs-3"> ${wishperData} </p>
        `;
    };
    wishperAction();
</script> -->

<script type="text/javascript">
    var recognizing;
    var recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    reset();
    recognition.onend = reset;

    recognition.onresult = function (event) {
        var final = "";
        var interim = "";
        for (var i = 0; i < event.results.length; ++i) {
            if (event.results[i].isFinal) {
                final += event.results[i][0].transcript;
            } else {
                interim += event.results[i][0].transcript;
            }
        }
        final_span.innerHTML = final;
        interim_span.innerHTML = interim;
    }

    function reset() {
        recognizing = false;
        button.innerHTML = "Click to Speak";
    }

    function toggleStartStop() {
        if (recognizing) {
            recognition.stop();
            reset();
        } else {
            recognition.start();
            recognizing = true;
            button.innerHTML = "Click to Stop";
            final_span.innerHTML = "";
            interim_span.innerHTML = "";
        }
    }
</script>
<script>
    const speechButton = document.getElementById("speechStart");
    const outputElement = document.getElementById("output");
    const recognition = new window.webkitSpeechRecognition();

    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = 'en-US';

    speechButton.addEventListener("mousedown", function () {
        this.classList.add("btn-outline-danger");
        this.classList.remove("btn-outline-light");
        this.textContent = 'Stop'
        // recognition.start();
    });

    speechButton.addEventListener("mouseup", () => {
        speechButton.classList.remove("btn-outline-danger");
        speechButton.classList.add("btn-outline-light");
        speechButton.textContent = 'Speech'

        // recognition.stop();
    });

    recognition.addEventListener("result", function (event) {
        const result = event.results[event.results.length - 1][0].transcript;
        outputElement.textContent = result;
    });



    // fetch('/transcription/', {
    //     method: 'POST',
    //     body: JSON.stringify({ transcript }),
    //     headers: {
    //         'Content-Type': 'application/json',
    //         'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value,
    //     },
    // });


</script>
{% endblock %}